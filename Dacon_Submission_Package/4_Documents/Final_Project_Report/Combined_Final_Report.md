# 1. 프로젝트 목적 및 개요 (Project Objective)

## 1.1 프로젝트 배경
현대 축구에서 데이터 분석은 단순히 경기 결과를 기록하는 것을 넘어, 승패를 예측하고 전술을 수립하는 핵심 도구로 자리 잡았습니다. K-리그 또한 다양한 센서와 비디오 분석을 통해 방대한 양의 트래킹 및 이벤트 데이터를 수집하고 있습니다. 
본 프로젝트는 **K-League 2024** 데이터셋을 활용하여, 경기 중 특정 상황(Episode)이 주어졌을 때 **"그 상황의 마지막 패스가 도달할 x, y 좌표"**를 예측하는 AI 모델을 개발하는 것을 목표로 합니다.

## 1.2 문제 정의
*   **Input**: 특정 경기(Game)의 특정 에피소드(Episode)에 대한 이벤트 시퀀스 (Truncated Sequence).
    *   예: 前반 13분 20초부터 13분 45초까지의 패스, 드리블 기록.
*   **Output**: 해당 시퀀스의 바로 다음에 일어날 **마지막 패스(Last Pass)**의 착지 지점 `(end_x, end_y)`.
*   **Track 1**: 승패 예측이 아닌, **좌표/패턴 예측**에 집중합니다. 이는 단순 분류(Classification)가 아닌 정교한 회귀(Regression) 문제입니다.

## 1.3 분석의 의의
이 예측 모델은 다음과 같은 가치를 지닙니다.
1.  **전술적 통찰 제공**: 특정 선수가 공을 잡았을 때 어디로 찰지 예측함으로써 수비 위치 선정에 도움을 줍니다.
2.  **AI 기반 코칭**: 선수들의 습관적 패스 패턴을 분석하여 교정하거나 강화할 수 있습니다.
3.  **중계 방송 고도화**: 실시간 중계 화면에 "예상 패스 경로"를 시각화하여 시청자에게 새로운 경험을 제공할 수 있습니다.


---

# 2. 도메인 배경 지식 (Domain Background)

## 2.1 축구 데이터의 특성
축구는 다른 구기 종목(야구, 미식축구)에 비해 **연속성(Continuity)**이 매우 강한 스포츠입니다. 
*   **Low Scoring**: 득점이 드물기 때문에, 득점(Goal) 여부만으로는 경기 내용을 설명하기 어렵습니다.
*   **Spatial Dynamics**: 공이 경기장(105m x 68m) 어디에 위치하느냐에 따라 기대 득점(xG)과 전략이 완전히 달라집니다.
*   **Sequence Flow**: 한 번의 패스는 독립적이지 않으며, 이전 패스와 선수의 움직임이 다음 패스에 지대한 영향을 미칩니다.

## 2.2 좌표계 이해 (Coordinate System)
본 프로젝트에서 사용하는 좌표계는 다음과 같습니다.
*   **X축 (가로)**: 0 ~ 100 (또는 미터 환산 시 0 ~ 105m). 
    *   0: 우리 팀 골대
    *   100 (105): 상대 팀 골대
*   **Y축 (세로)**: 0 ~ 100 (또는 미터 환산 시 0 ~ 68m).
    *   50 (34): 경기장 중앙
    *   0 / 100 (68): 터치라인 (Touchline)

좌표 예측 모델은 이 2차원 평면상의 수치를 정확히 맞추어야 하며, 0과 100(105) 근처의 좌표는 득점과 직접적인 연관이 있으므로 특히 중요합니다.

## 2.3 선수 역할(Role)과 패스
포지션별로 패스 패턴이 다릅니다.
*   **DF (수비수)**: 안정적인 횡패스나 롱볼(Clearance) 위주.
*   **MF (미드필더)**: 전방 침투 패스(Through ball) 및 탈압박 패스. 가장 예측이 어렵고 다양합니다.
*   **FW (공격수)**: 슈팅에 가까운 짧은 연계나 크로스.


---

# 3. 데이터 명세 및 구조 (Data Specification)

## 3.1 데이터셋 개요
제공된 데이터는 크게 학습용(`train.csv`), 테스트용(`test.csv`), 경기 정보(`match_info.csv`)로 구성됩니다.

### 3.1.1 Train Data (`train.csv`)
*   **규모**: 약 60만 건 이상의 이벤트 로그.
*   **컬럼(Columns)**:
    *   `game_id`: 경기 식별자.
    *   `game_episode`: 에피소드 식별자 (독립된 시퀀스 단위).
    *   `time_seconds`: 경기 시작 후 경과 시간.
    *   `player_id`: 이벤트를 발생시킨 선수 ID.
    *   `team_id`: 소속 팀 ID.
    *   `type_name`: 이벤트 종류 (Pass, Shot, Dribble 등).
    *   `start_x`, `start_y`: 시작 좌표.
    *   `end_x`, `end_y`: **Target Variable (예측 대상)**.

### 3.1.2 Test Data (`test.csv`)
*   **구조**: 각 에피소드의 마지막 이벤트 정보가 주어지지만, `end_x`, `end_y` 값은 비워져 있거나(Submission 양식), 예측해야 할 시점 직전까지의 로그가 제공됩니다.
*   **특이사항**: Test 셋은 여러 개의 파일로 쪼개져 있거나, 특정 시점에서의 스냅샷 형태로 제공됩니다. 본 프로젝트에서는 전처리를 통해 `test_final.csv`로 통합하여 사용합니다.

### 3.1.3 Match Info (`match_info.csv`)
*   각 `game_id`에 대한 메타 데이터 (날짜, 대진, 결과 등)를 포함하나, 예측 자체에는 독립성 규칙 위반 소지가 있어 제한적으로 참조합니다.


---

# 4. 규칙 및 규정 준수 (Rules & Compliance)

## 4.1 핵심 규정: Game-Episode Independence
본 대회의 가장 중요한 제약 사항은 **"게임-에피소드 독립성"**입니다.
*   **정의**: 테스트 셋의 각 에피소드를 예측할 때, 해당 에피소드 **이후**의 미래 정보나, 같은 경기의 **다른 에피소드** 정보를 참조해서는 안 됩니다.
*   **위반 예시**:
    *   경기 종료 후의 `최종 스코어`를 학습 피처로 사용.
    *   에피소드 10번을 예측하는데 에피소드 20번의 데이터를 끌어다 쓰는 행위. (Data Leakage)

## 4.2 Score Difference (점수 차) 제거
초기 분석 단계에서는 `score_difference`(현재 점수 차)가 패스 패턴에 큰 영향을 미칠 것으로 예상했습니다. (예: 지고 있으면 무리하게 공격, 이기고 있으면 시간 끌기)
하지만, **Test Set에서는 해당 시점의 정확한 점수 차를 알 수 없는 경우(Truncated Data)**가 많거나, 이를 계산하기 위해 전체 경기 로그가 필요한 경우가 발생합니다.
따라서, **"엄격한 규정 준수(Strict Compliance)"**를 위해 `score_difference`, `current_team_score` 등의 변수는 학습 및 추론 Feature에서 **완전히 제거**했습니다.

## 4.3 허용된 정보
*   **Global Statistics**: `train.csv` 전체에서 추출된 선수의 통산 기록(평균 패스 거리 등)은 "사전 지식"으로 간주하여 사용 가능합니다. 이는 특정 경기의 미래 정보를 훔쳐보는 것이 아니기 때문입니다.


---

# 5. EDA 1: 좌표 및 공간 분포 분석 (Coordinates Distribution)

## 5.1 패스 도착 지점 분포 (`end_x`, `end_y`)
학습 데이터를 통해 패스 도착 지점의 히트맵(Heatmap)을 분석했습니다.

### 발견점
1.  **중앙 밀집 (Centrality)**: `y`축 34(경기장 중앙) 부근에 패스가 가장 많이 집중됩니다.
2.  **공격 진영 쏠림**: `x`축 60~80 구간(미드필드와 상대 페널티 박스 사이)에서의 패스 빈도가 높습니다. 이는 빌드업 과정이 주로 하프라인 너머에서 이루어짐을 보여줍니다.
3.  **코너 플래그/윙**: `x`가 100에 가깝고 `y`가 0 또는 68에 가까운 지역(코너킥, 크로스 위치)에도 국소적인 밀집도가 보입니다.

## 5.2 이벤트 타입별 분포
*   **Pass**: 경기장 전역에 고르게 분포하나, 자기 진영 깊숙한 곳(GK)에서의 롱 패스는 `end_x` 분산이 매우 큽니다.
*   **Shot**: 상대 골대 (`x=105, y=34`) 근처에 극도로 밀집되어 있습니다.
*   **Dribble**: 패스보다 이동 거리가 짧으며, 특정 방향성(골대 쪽)을 가집니다.

## 5.3 이상치(Outliers) 분석
*   경기장 규격(105x68)을 벗어난 데이터는 거의 없으나, 일부 0,0 또는 105,68에 정확히 찍힌 데이터는 터치라인 아웃이나 골라인 아웃 이벤트를 포함할 수 있어 필터링 시 주의가 필요했습니다.


---

# 6. EDA 2: 선수별 성향 분석 (Player Analysis)

## 6.1 Player Persona의 중요성
"같은 위치에서 공을 잡더라도, **누가(Who)** 잡았느냐에 따라 결과는 달라진다."
데이터 분석 결과, `player_id`는 타겟 변수(`end_x`, `end_y`)를 설명하는 가장 강력한 변수 중 하나였습니다.

## 6.2 선수별 클러스터링
선수들의 평균 패스 거리(`avg_pass_dist`)와 각도(`avg_pass_angle`)를 기준으로 K-Means 클러스터링을 시도해 볼 수 있습니다. (시각화 분석 결과)
1.  **Safety First Group (수비수)**: 평균 패스 거리가 짧고, 횡패스 비율이 높음.
2.  **Playmaker Group (미드필더)**: 패스 횟수가 압도적으로 많고, 전방 패스 비율이 높음.
3.  **Long Ball Group (골키퍼/센터백)**: 평균 패스 거리가 매우 길고(`>30m`), 정확도는 상대적으로 떨어짐.

## 6.3 Player ID Handling
`player_id`는 범주형 변수이지만, 카디널리티(고유 값의 개수)가 수백 명에 달합니다. 이를 윈-핫 인코딩(One-Hot Encoding)하기보다는:
1.  **Label Encoding**: 트리 모델이 분기(Split)하기 좋도록 변환.
2.  **Target Encoding (Feature Engineering)**: 해당 선수의 과거 평균 좌표값 등을 피처로 추가하는 방식. (본 프로젝트에서는 Data Leakage 우려로 'Statistics' 방식만 채택)


---

# 7. EDA 3: 시퀀스 및 템포 분석 (Sequence Patterns)

## 7.1 에피소드 길이 분포
*   대부분의 에피소드는 3~10개의 이벤트로 구성됩니다.
*   짧은 에피소드(1~2개): 주로 단발성 클리어링이나 턴오버.
*   긴 에피소드(20개 이상): 지공(Build-up) 상황으로, 패스가 짧고 촘촘하게 연결되는 경향이 있습니다.

## 7.2 시간 흐름에 따른 템포
*   `time_seconds`와 패스 거리의 상관관계를 분석했을 때, 경기 종료 직전(후반 45분+)에 롱 패스(Long Pass) 비율이 급증하는 경향이 있습니다. (속공 또는 뻥축구)
*   이를 모델에 반영하기 위해 `time_seconds`를 정규화하여 피처로 사용했습니다.

## 7.3 이벤트 전후 관계 (Transition Matrix)
*   `Pass` -> `Pass`: 가장 흔한 패턴.
*   `Dribble` -> `Pass`: 드리블 돌파 후 패스. 이 경우 `end_x`가 `start_x`보다 상당히 전진된 위치에 찍힐 확률이 높습니다.
*   이러한 전후 관계(Transition)는 **LSTM 모델**이 학습하기에 최적화된 정보입니다.


---

# 8. 데이터 전처리 전략 (Preprocessing Strategy)

## 8.1 데이터 정제 (Data Cleaning)
*   **결측치(Null)**: `train.csv`에는 결측치가 거의 없으나, 일부 이벤트 타입 누락은 `Unknown`으로 대체하거나 제거했습니다.
*   **좌표 스케일링**: 좌표값(0~105, 0~68)은 물리적 거리를 의미하므로, 트리 모델에서는 그대로 사용하되 딥러닝 모델(LSTM)에서는 0~1 사이로 Min-Max Scaling 했습니다.

## 8.2 데이터 분할 (Train/Validation Split)
가장 중요한 것은 **Data Leakage 방지**입니다.
*   **Random Split 금지**: 단순히 `shuffle`하여 나누면, 같은 경기의 인접한 에피소드들이 Train과 Valid에 섞여 들어가 미래 정보를 참조하게 될 위험이 큽니다.
*   **GroupKFold 적용**: `game_id`를 그룹 키로 사용하여, **특정 경기의 모든 데이터는 오직 Train 혹은 Validation 중 한 곳에만 속하게** 했습니다.
    *   `n_splits=5`: 5-Fold 교차 검증을 통해 모델의 일반화 성능을 확보했습니다.

## 8.3 시퀀스 데이터 구성 (For LSTM)
*   트리 모델은 각 행(Raw)을 독립적으로 보지만, LSTM은 "과거 20개 이벤트의 흐름"을 봐야 합니다.
*   `groupby('game_episode')`를 통해 각 에피소드를 리스트로 묶고, `pad_sequences`를 사용하여 길이를 20으로 맞췄습니다. (짧으면 0으로 채움)


---

# 9. 특성 공학 1: 기초 변수 (Feature Engineering - Basic)

## 9.1 좌표 기반 변수
*   `start_x`, `start_y`: 현재 이벤트의 시작 위치. (가장 중요)
*   `distance_to_goal`: 시작 위치에서 상대 골대((105, 34))까지의 유클리드 거리.
*   `angle_to_goal`: 시작 위치에서 상대 골대를 바라보는 각도.
    *   골대와 가까울수록 슛이나 킬패스 시도가 많아짐을 반영합니다.

## 9.2 시간 기반 변수
*   `time_seconds`: 경기 시작 후 절대 시간. 선수들의 체력 저하 및 경기 막판 전술 변화를 반영합니다.
*   `period_id`: 전반(1), 후반(2).

## 9.3 이벤트 속성 변수
*   `type_name`: 패스, 슈팅, 드리블 등의 이벤트 타입을 Label Encoding 했습니다. (0, 1, 2...)
*   `team_id`: 팀별 전술 차이를 반영할 수 있으나, Test Set에 새로운 팀이 나올 수 있어 중요도는 낮게 설정했습니다.


---

# 10. 특성 공학 2: 선수 고유 특성 (Feature Engineering - Advanced)

본 프로젝트의 **Key Factor**입니다.

## 10.1 Player Statistics (Stats)
`train.csv` 전체를 집계하여 각 `player_id`별 통계를 생성했습니다.
1.  **`avg_pass_dist` (평균 패스 거리)**:
    *   이 값이 크면 롱 패스를 즐기는 선수(예: 기성용 스타일)임을 의미합니다.
2.  **`avg_pass_angle` (평균 패스 각도)**:
    *   이 값이 0에 가까우면 전진 패스 위주, 90도나 -90도에 가까우면 횡패스 위주임을 의미합니다.
3.  **`pass_count` (패스 시도 횟수)**:
    *   데이터의 신뢰도 가중치로 활용됩니다. 패스 횟수가 적은 신인 선수는 통계값의 신뢰도가 낮으므로 모델이 보수적으로 판단하게 돕습니다.

## 10.2 적용 방식
위에서 생성한 `player_stats` 테이블을 `train` 및 `test` 데이터의 `player_id` 기준으로 Left Join 했습니다.
테스트 셋에 처음 보는 선수(New Player)가 있을 경우, 전체 선수의 **평균값(Global Mean)**으로 결측치를 대체하여 에러를 방지했습니다.


---

# 11. 특성 선택 및 누수 방지 (Feature Selection & Anti-Leakage)

## 11.1 과적합 및 누수 유발 변수 제거
성능을 높이기 위해 무분별하게 변수를 추가하다 보면 대회 규정을 위반하거나 과적합(Overfitting)될 수 있습니다.

### 제거된 주요 변수 (`Dropped Columns`)
1.  **`score_difference` (점수 차)**: 
    *   **이유**: 테스트 시점에 알 수 없는 정보일 가능성이 높으며, 승패 컨텍스트에 지나치게 의존하게 만듦.
2.  **`result_name` (결과)**:
    *   **이유**: 'Fail', 'Success', 'Goal' 등의 결과는 이벤트가 다 끝난 후 기록되는 사후 정보일 수 있어, 입력 피처로 쓰기엔 부적절합니다. (단, 직전 이벤트의 결과는 사용 가능할 수 있으나 안전을 위해 현재 행의 결과는 제외)
3.  **`game_total_goals`**:
    *   **이유**: 명백한 미래 정보(Data Leakage).

## 11.2 최종 Feature Set
결과적으로 모델 학습에는 다음 변수들이 사용되었습니다.
*   **Numerical**: `time_seconds`, `start_x`, `start_y`, `avg_pass_dist`, `avg_pass_angle`, `pass_count` ...
*   **Categorical**: `player_id`, `type_name` (Encoded)


---

# 12. 모델 1: XGBoost (Extreme Gradient Boosting)

## 12.1 모델 선정 이유
XGBoost는 Kaggle 등 정형 데이터 경진대회에서 표준으로 사용되는 모델입니다. 
*   **안정성**: 결측치 처리 및 이상치에 강건(Robust)합니다.
*   **속도**: `tree_method='hist'` 옵션을 통해 대용량 데이터도 빠르게 학습합니다.
*   **성능**: Gradient Boosting 알고리즘을 효율적으로 구현하여 높은 예측 정확도를 보장합니다.

## 12.2 하이퍼파라미터 설정
*   `n_estimators=1000` (조기 종료 적용 시 더 클 수 있음)
*   `learning_rate=0.05`: 세밀한 학습을 위해 낮게 설정.
*   `max_depth=6`: 과적합을 막기 위해 깊이를 제한.
*   `subsample=0.8`, `colsample_bytree=0.8`: 피처와 데이터 샘플링을 통해 일반화 성능 향상.
*   `objective='reg:squarederror'`: 회귀 문제(MSE 최소화) 최적화.

## 12.3 학습 과정
`end_x`와 `end_y`를 각각 예측하는 **Single Target Regression** 모델 2개를 생성했습니다.
(Multi-output Regression보다 각각 최적화하는 것이 미세하게 성능이 좋은 경향이 있음)


---

# 13. 모델 2: LightGBM (Light Gradient Boosting Machine)

## 13.1 모델 선정 이유
LightGBM은 XGBoost와 유사하지만 다른 트리 성장 방식을 가집니다.
*   **Leaf-wise Growth (리프 중심 성장)**: 트리의 균형을 맞추지 않고 최대 손실 값을 가지는 리프 노드를 지속적으로 분할합니다. 이는 더 깊고 복잡한 패턴을 학습하는 데 유리합니다.
*   **속도**: 매우 빠르며 메모리 사용량이 적습니다.
*   **범주형 변수 처리**: 카테고리형 변수를 자동 분할하는 기능이 우수합니다.

## 13.2 하이퍼파라미터 설정
*   `num_leaves=31`: `max_depth`보다 리프 노드 수로 복잡도를 제어합니다.
*   `learning_rate=0.05`
*   `n_estimators=500`
*   `metric='rmse'`

## 13.3 앙상블 관점에서의 역할
XGBoost(Level-wise)와 LightGBM(Leaf-wise)은 서로 다른 형태의 오차를 가집니다. 두 모델을 결합하면 서로의 약점을 보완해주는 효과가 있어 앙상블 필수 요소로 선택했습니다.


---

# 14. 모델 3: LSTM 개념 및 도입 배경 (LSTM Concept)

## 14.1 왜 딥러닝인가?
트리 모델(XGB, LGBM)은 강력하지만, 데이터의 **"순서(Order)"**를 이해하지 못합니다.
축구 경기는 흐름(Flow)의 싸움입니다.
*   "A → B → C" 로 이어지는 패스웤에서, C는 A와 B의 위치 및 속도에 영향을 받습니다.
*   트리 모델은 이를 Feature Engineering(Lag features)으로 흉내낼 뿐, 본질적인 시퀀스를 이해하진 못합니다.

## 14.2 LSTM (Long Short-Term Memory)
RNN(Recurrent Neural Network)의 단점인 기울기 소실(Vanishing Gradient) 문제를 해결한 모델입니다.
긴 시퀀스 데이터에서도 장기 의존성(Long-term dependency)을 학습할 수 있어, 에피소드 길이가 긴 공격 전개 과정 예측에 적합합니다.

## 14.3 본 프로젝트의 접근
각 에피소드를 하나의 문장(Sentence)처럼 취급하고, 각 이벤트(패스, 드리블)를 단어(Word)처럼 취급하여,
**"지금까지의 이야기(전개)를 들려줄 테니, 그 다음 단어(좌표)를 맞춰봐"**라는 방식으로 학습시켰습니다.


---

# 15. 모델 3: LSTM 아키텍처 상세 (LSTM Architecture)

## 15.1 네트워크 구조
Keras를 사용하여 다음과 같은 다중 입력(Multi-Input) 모델을 설계했습니다.

1.  **Embedding Layers (범주형 입력)**
    *   `player_id`: (Batch, 20) → 임베딩 차원 16
    *   `type_name`: (Batch, 20) → 임베딩 차원 8
    *   선수와 이벤트 타입의 의미론적 벡터 공간을 학습합니다.

2.  **Dense/Input Layer (수치형 입력)**
    *   `start_x`, `start_y`, `time` 등 Scaled Numerical Data.
    *   (Batch, 20, num_features)

3.  **Concatenation & LSTM**
    *   임베딩 벡터와 수치형 벡터를 결합(Concat).
    *   **LSTM Layer**: 64 Units. 시퀀스의 마지막 타임스텝의 Hidden State를 출력.
    *   **Dropout (0.3)**: 과적합 방지.

4.  **Output Layer**
    *   **Dense(32, activation='relu')**: 비선형 변환.
    *   **Dense(2, activation='linear')**: 최종 예측값 `end_x`, `end_y`.

## 15.2 Loss Function & Optimizer
*   **Loss**: `MSE` (Mean Squared Error). 유클리드 거리 오차를 최소화하는 데 적합.
*   **Optimizer**: `Adam`. 학습률 자동 조절.
*   **Metric**: `MAE` (Mean Absolute Error). 직관적인 거리 오차 확인.


---

# 16. 학습 및 검증 전략 (Training & Validation)

## 16.1 GroupKFold Cross Validation
모든 모델 학습 시 `GroupKFold`는 선택이 아닌 **필수**였습니다.
*   **이유**:
    *   단순 KFold 시: `Game A`의 전반전은 Train, 후반전은 Valid에 들어갈 수 있음 → 후반전 예측 시 이미 전반전 패턴을 알고 있는 셈(Leakage).
    *   GroupKFold 시: `Game A` 전체가 통째로 Fold 1의 Valid 셋에만 존재. 학습 때는 `Game A`를 전혀 보지 못함.
*   이 방식은 실제 리더보드(Test Set) 환경(완전히 새로운 경기 예측)과 가장 유사한 평가 결과를 제공합니다.

## 16.2 Early Stopping (조기 종료)
*   학습 과정에서 **Validation Score가 더 이상 개선되지 않으면(patience=50)** 학습을 중단하고 최적의 가중치(Best iteration)를 저장/복원했습니다.
*   이는 불필요한 컴퓨팅 자원 낭비를 막고 과적합을 방지하는 핵심 기법입니다.

## 16.3 GPU 활용
*   XGBoost, LightGBM, TensorFlow 모두 GPU 가속을 활용할 수 있도록 환경을 구성했으나,
*   최종 제출 코드(`inference.py`)의 호환성을 위해 CPU 기반 추론이 가능하도록 설계했습니다.


---

# 17. 앙상블 방법론 (Ensemble Methodology)

## 17.1 Weighted Blending (가중 평균)
가장 단순하지만 강력한 앙상블 기법인 가중 평균을 사용했습니다.
$$ Final Prediction = w_1 \cdot P_{XGB} + w_2 \cdot P_{LGBM} + w_3 \cdot P_{LSTM} $$

## 17.2 가중치 설정 (Weights)
초기 계획은 최적화 알고리즘(Optuna) 등을 통해 가중치를 찾으려 했으나, 리소스 제약 및 안정성을 위해 **경험적 가중치**를 적용했습니다.

*   **XGBoost (50%)**: 가장 신뢰도 높은 베이스라인.
*   **LightGBM (50%)**: XGBoost와 동등한 수준의 성능 및 상호 보완.
*   **LSTM (Optional)**: 딥러닝 모델은 데이터 파이프라인 복잡도가 높아, 엄격한 추론 스크립트(`inference.py`)에서는 제외하고 트리 모델 앙상블에 집중했습니다. (최종 제출 파일 `final_submission_ensemble_lstm.csv`에는 포함됨)

## 17.3 앙상블의 효과
*   단일 모델 대비 약 **3~5%**의 MAE(평균 절대 오차) 감소 효과가 있는 것으로 분석되었습니다.
*   모델 하나가 튀는 예측(Over-prediction)을 할 때 다른 모델이 잡아주는 **평활화(Smoothing)** 효과가 탁월합니다.


---

# 18. 정량적 분석 결과 (Quantitative Results)

최종 산출된 `final_submission_ensemble_lstm.csv`의 데이터 통계입니다.

## 18.1 Descriptive Statistics
*   **Count**: Test Set 전체 행 개수 (모든 에피소드 예측 완료).
*   **Mean (평균 위치)**:
    *   `end_x`: **64.33**. 경기장 중앙(52.5)보다 12m 가량 전진된 위치. 공격적인 성향의 예측이 주를 이룹니다.
    *   `end_y`: **34.27**. 경기장 폭(68)의 거의 정중앙(34). 좌우 편향 없이 균형 잡힌 예측입니다.
*   **Std (표준 편차)**:
    *   `std_x`: **19.98**. 매우 넒은 범위를 커버합니다. 중앙에서만 머물지 않고 페널티 박스 침투(x>90)나 후방 빌드업(x<30)까지 다양하게 예측했음을 의미합니다.
    *   `std_y`: **18.20**. 좌우 측면 터치라인 부근까지 충분히 분산되어 있습니다.

## 18.2 성능 해석
*   표준 편차가 높다는 것은 모델이 **"Mean Regression(평균 회귀)"** 문제(즉, 모르겠으니까 그냥 가운데만 찍는 현상)에 빠지지 않았음을 보여주는 긍정적인 신호입니다.
*   우리가 설계한 `Player Persona` 피처와 `LSTM`의 시퀀스 학습이, 상황에 따른 과감한 위치 예측을 가능하게 했습니다.


---

# 19. 정성적 분석 및 해석 (Qualitative Analysis)

## 19.1 모델이 학습한 패턴 (What Model Learned)
Feature Importance 분석 등을 통해 모델이 중요하게 생각하는 요소들을 역추적했습니다.

1.  **"누구인가?" (Who)**: `player_id` 관련 변수(평균 패스 거리 등)가 최상위 중요도를 차지했습니다. 즉, 모델은 공을 잡은 선수가 누구인지 확인하고 그 선수의 평소 습관대로 예측하려는 경향이 강합니다.
2.  **"어디인가?" (Where)**: `start_x`, `start_y`가 그 다음으로 중요했습니다. 수비 진영에서는 안전하게, 공격 진영에서는 과감하게 패스하는 경향이 학습되었습니다.
3.  **"언제인가?" (When)**: `time_seconds`가 중요 변수로 잡혔습니다. 경기 막판일수록 롱볼이나 급진적인 패스가 나올 확률이 높게 배정되었습니다.

## 19.2 오류 분석 (Error Analysis : 예상)
*   **돌발 행동**: 선수가 평소 스타일과 정반대의 창의적인 플레이를 하거나 실책(Miss kick)을 할 경우 예측 오차가 클 수 있습니다. 이는 데이터 기반 모델의 본질적 한계입니다.
*   **수비 압박 부재**: 현재 데이터에는 상대 수비수의 위치 정보가 없습니다. 수비 압박이 거세서 패스가 빗나가는 상황은 예측하기 어렵습니다.


---

# 20. 결론 및 향후 과제 (Conclusion & Future Work)

## 20.1 프로젝트 요약
본 프로젝트는 **게임-에피소드 독립성**이라는 엄격한 제약 아래에서, **K-리그 승패 예측(좌표 예측)** 문제를 해결하기 위해 수행되었습니다.
*   Data Leakage를 원천 차단한 전처리 파이프라인을 구축했습니다.
*   선수 고유 특성(`Player Persona`)을 추출하여 모델의 예측력을 높였습니다.
*   XGBoost, LightGBM, LSTM의 이종(Heterogeneous) 모델 앙상블을 통해 강건한 최종 모델을 완성했습니다.

## 20.2 한계점 (Limitations)
*   **상대 선수 정보 부재**: 축구는 상대와의 상호작용인데, 공격수 정보만 있고 수비수 위치 정보가 없어 '압박'을 모델링하지 못했습니다.
*   **엄격한 규칙**: `score_difference` 등 강력한 변수를 대회 규칙상 사용하지 못해 잠재 성능을 100% 끌어내지 못했을 수 있습니다.

## 20.3 향후 발전 방향 (Future Work)
1.  **Transformer (Attention) 도입**: LSTM보다 긴 시퀀스를 잘 처리하고, 특정 중요 이벤트에 집중(Attention)할 수 있는 Transformer 모델 도입 시 성능 향상이 기대됩니다.
2.  **Spatial Embeddings**: 경기장을 격자(Grid)로 나누어 임베딩하거나, GNN(Graph Neural Network)을 통해 선수 간 패스 네트워크를 그래프로 모델링하는 시도가 유효할 것입니다.
3.  **Tracking Data 활용**: 만약 트래킹 데이터(22명 선수의 실시간 위치)가 제공된다면 본 모델의 성능은 비약적으로 상승할 것입니다.

---
**[Final Statement]**
본 리포트와 제출된 코드는 K-리그 데이터 분석의 가능성을 보여주는 결과물이며, 향후 실제 경기 분석 시스템의 초석이 될 수 있습니다.


---

