{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51df454",
   "metadata": {},
   "source": [
    "# Model 3. CatBoost + Optuna Tuning\n",
    "\n",
    "범주형 데이터 처리에 특화된 **CatBoost**를 사용하여 모델을 학습시킵니다.\n",
    "과적합을 방지하는 기능이 강력하며, 하이퍼파라미터에 덜 민감하여 기본 설정으로도 좋은 성능을 보여줍니다.\n",
    "\n",
    "### 진행 순서\n",
    "1.  데이터 로드 (train_enriched.csv, test_enriched.csv)\n",
    "2.  데이터 인코딩 (Label Encoding)\n",
    "3.  Optuna를 이용한 하이퍼파라미터 최적화\n",
    "4.  최적의 파라미터로 최종 모델 학습\n",
    "5.  결과 예측 및 제출 파일 생성 (submission_cat_optuna.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63381fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jwk72\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-12-02 14:28:20,814] A new study created in memory with name: no-name-a065238a-6bc5-4c1c-bded-46aed816c107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중...\n",
      "학습 데이터 준비 완료: (12348, 11)\n",
      "\n",
      "Optuna 튜닝 시작 (20회 시도)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-02 14:28:23,597] Trial 0 finished with value: 13.713961111221387 and parameters: {'iterations': 253, 'learning_rate': 0.1777800739886037, 'depth': 7, 'l2_leaf_reg': 1.6212951527004487, 'subsample': 0.6801982652228796}. Best is trial 0 with value: 13.713961111221387.\n",
      "[I 2025-12-02 14:28:29,034] Trial 1 finished with value: 14.185141123397061 and parameters: {'iterations': 562, 'learning_rate': 0.2870647513405434, 'depth': 7, 'l2_leaf_reg': 3.2386004073919663, 'subsample': 0.754000965932448}. Best is trial 0 with value: 13.713961111221387.\n",
      "[I 2025-12-02 14:28:30,624] Trial 2 finished with value: 13.508666578775408 and parameters: {'iterations': 257, 'learning_rate': 0.07742709050617362, 'depth': 5, 'l2_leaf_reg': 7.038044655266594, 'subsample': 0.779465674493662}. Best is trial 2 with value: 13.508666578775408.\n",
      "[I 2025-12-02 14:28:33,997] Trial 3 finished with value: 13.505341154434241 and parameters: {'iterations': 143, 'learning_rate': 0.10367844403300458, 'depth': 9, 'l2_leaf_reg': 5.763204486372212, 'subsample': 0.827447675141186}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:28:35,885] Trial 4 finished with value: 13.563521973671213 and parameters: {'iterations': 370, 'learning_rate': 0.16280558764134423, 'depth': 4, 'l2_leaf_reg': 7.97118507663701, 'subsample': 0.811424838738353}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:28:37,254] Trial 5 finished with value: 13.726079254801114 and parameters: {'iterations': 205, 'learning_rate': 0.016456481753513823, 'depth': 5, 'l2_leaf_reg': 9.555062253615219, 'subsample': 0.7360399244574336}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:28:43,694] Trial 6 finished with value: 14.114833953217403 and parameters: {'iterations': 640, 'learning_rate': 0.21433173472997638, 'depth': 7, 'l2_leaf_reg': 3.6966355697814883, 'subsample': 0.7957999802659013}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:28:48,326] Trial 7 finished with value: 14.054054915470907 and parameters: {'iterations': 635, 'learning_rate': 0.2481533470231616, 'depth': 6, 'l2_leaf_reg': 6.129610701249348, 'subsample': 0.8951091303881202}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:28:55,307] Trial 8 finished with value: 14.252900912760321 and parameters: {'iterations': 902, 'learning_rate': 0.2636852005683329, 'depth': 6, 'l2_leaf_reg': 4.1355140643897075, 'subsample': 0.6902785310083203}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:29:01,457] Trial 9 finished with value: 14.250943960512135 and parameters: {'iterations': 805, 'learning_rate': 0.29220833613231617, 'depth': 6, 'l2_leaf_reg': 8.137353664377626, 'subsample': 0.7982064614958772}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:29:06,694] Trial 10 finished with value: 13.529279538117997 and parameters: {'iterations': 103, 'learning_rate': 0.09624950272406671, 'depth': 10, 'l2_leaf_reg': 5.248698102087089, 'subsample': 0.9888081339216344}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:29:26,319] Trial 11 finished with value: 13.656638332457105 and parameters: {'iterations': 390, 'learning_rate': 0.08828690704152735, 'depth': 10, 'l2_leaf_reg': 6.604984628814412, 'subsample': 0.8970710096939732}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:29:35,999] Trial 12 finished with value: 13.618232032910454 and parameters: {'iterations': 384, 'learning_rate': 0.09732209747432066, 'depth': 9, 'l2_leaf_reg': 7.747296037817009, 'subsample': 0.8750421192657425}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:29:38,440] Trial 13 finished with value: 13.590299876730098 and parameters: {'iterations': 100, 'learning_rate': 0.03593550759371281, 'depth': 9, 'l2_leaf_reg': 5.750351474293892, 'subsample': 0.8472574664756984}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:29:39,871] Trial 14 finished with value: 13.538621557787792 and parameters: {'iterations': 273, 'learning_rate': 0.12876707006406957, 'depth': 4, 'l2_leaf_reg': 9.781621883902034, 'subsample': 0.6269257832689894}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:29:46,852] Trial 15 finished with value: 13.568973843383274 and parameters: {'iterations': 461, 'learning_rate': 0.057485539236478936, 'depth': 8, 'l2_leaf_reg': 4.6753170864297005, 'subsample': 0.9673175139577933}. Best is trial 3 with value: 13.505341154434241.\n",
      "[I 2025-12-02 14:29:49,881] Trial 16 finished with value: 13.456294476097703 and parameters: {'iterations': 200, 'learning_rate': 0.06563154654477267, 'depth': 8, 'l2_leaf_reg': 7.212929810822191, 'subsample': 0.9372108026847834}. Best is trial 16 with value: 13.456294476097703.\n",
      "[I 2025-12-02 14:29:52,507] Trial 17 finished with value: 13.575014337954535 and parameters: {'iterations': 168, 'learning_rate': 0.13095399385266726, 'depth': 8, 'l2_leaf_reg': 2.5683895777589685, 'subsample': 0.9382089894188272}. Best is trial 16 with value: 13.456294476097703.\n",
      "[I 2025-12-02 14:30:00,172] Trial 18 finished with value: 13.686496942420836 and parameters: {'iterations': 320, 'learning_rate': 0.13036932760327036, 'depth': 9, 'l2_leaf_reg': 8.842737110717085, 'subsample': 0.9298902646755793}. Best is trial 16 with value: 13.456294476097703.\n",
      "[I 2025-12-02 14:30:07,445] Trial 19 finished with value: 13.519455028586371 and parameters: {'iterations': 482, 'learning_rate': 0.05050337118867582, 'depth': 8, 'l2_leaf_reg': 7.282203194776274, 'subsample': 0.8451007457999757}. Best is trial 16 with value: 13.456294476097703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Trial: 13.4563\n",
      "Best Params: {'iterations': 200, 'learning_rate': 0.06563154654477267, 'depth': 8, 'l2_leaf_reg': 7.212929810822191, 'subsample': 0.9372108026847834}\n",
      "\n",
      "최적 파라미터로 전체 데이터 재학습 중...\n",
      "\n",
      "CatBoost 튜닝 완료! 결과 저장됨: submission_cat_optuna.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. 데이터 로드 및 준비\n",
    "PREPROCESS_DIR = './data_preprocess'\n",
    "SUBMISSION_DIR = './open_track1'\n",
    "\n",
    "TRAIN_PATH = os.path.join(PREPROCESS_DIR, 'train_enriched.csv')\n",
    "TEST_PATH = os.path.join(PREPROCESS_DIR, 'test_enriched.csv')\n",
    "SUBMISSION_PATH = os.path.join(SUBMISSION_DIR, 'sample_submission.csv')\n",
    "\n",
    "print(\"데이터 로딩 중...\")\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# 인코딩\n",
    "cat_features = ['type_name', 'prev_type_name']\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in cat_features:\n",
    "    all_values = pd.concat([train_df[col].astype(str), test_df[col].astype(str)]).unique()\n",
    "    le.fit(all_values)\n",
    "    train_df[col] = le.transform(train_df[col].astype(str))\n",
    "    test_df[col] = le.transform(test_df[col].astype(str))\n",
    "\n",
    "# 피처 선택\n",
    "feature_cols = [\n",
    "    'start_x', 'start_y', 'type_name', 'team_id', 'time_seconds',\n",
    "    'prev_type_name', 'prev_end_x', 'prev_end_y',\n",
    "    'dist_to_goal', 'angle_to_goal', 'dist_to_center'\n",
    "]\n",
    "target_cols = ['end_x', 'end_y']\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df[target_cols]\n",
    "X_test = test_df[feature_cols]\n",
    "test_ids = test_df['game_episode']\n",
    "\n",
    "# 튜닝용 데이터 분리 (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"학습 데이터 준비 완료: {X_train.shape}\")\n",
    "\n",
    "# 2. Optuna를 이용한 하이퍼파라미터 튜닝\n",
    "def objective(trial):\n",
    "    # 튜닝할 파라미터 범위 설정\n",
    "    params = {\n",
    "        'loss_function': 'RMSE',\n",
    "        'verbose': False,\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'random_seed': 42\n",
    "    }\n",
    "    \n",
    "    # X축 예측 모델\n",
    "    model_x = CatBoostRegressor(**params)\n",
    "    model_x.fit(X_train, y_train['end_x'])\n",
    "    pred_x = model_x.predict(X_val)\n",
    "    \n",
    "    # Y축 예측 모델\n",
    "    model_y = CatBoostRegressor(**params)\n",
    "    model_y.fit(X_train, y_train['end_y'])\n",
    "    pred_y = model_y.predict(X_val)\n",
    "    \n",
    "    # 평균 RMSE 계산\n",
    "    rmse_x = np.sqrt(mean_squared_error(y_val['end_x'], pred_x))\n",
    "    rmse_y = np.sqrt(mean_squared_error(y_val['end_y'], pred_y))\n",
    "    \n",
    "    return (rmse_x + rmse_y) / 2\n",
    "\n",
    "print(\"\\nOptuna 튜닝 시작 (20회 시도)...\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(f\"\\nBest Trial: {study.best_trial.value:.4f}\")\n",
    "print(\"Best Params:\", study.best_params)\n",
    "\n",
    "# 3. 최적 파라미터로 최종 학습 및 예측\n",
    "print(\"\\n최적 파라미터로 전체 데이터 재학습 중...\")\n",
    "\n",
    "best_params = study.best_params\n",
    "best_params['loss_function'] = 'RMSE'\n",
    "best_params['verbose'] = False\n",
    "best_params['random_seed'] = 42\n",
    "\n",
    "# 전체 데이터로 학습\n",
    "final_model_x = CatBoostRegressor(**best_params)\n",
    "final_model_y = CatBoostRegressor(**best_params)\n",
    "\n",
    "final_model_x.fit(X, y['end_x'])\n",
    "final_model_y.fit(X, y['end_y'])\n",
    "\n",
    "# 예측\n",
    "pred_x = final_model_x.predict(X_test)\n",
    "pred_y = final_model_y.predict(X_test)\n",
    "\n",
    "# Clipping (경기장 규격 보정)\n",
    "pred_x = np.clip(pred_x, 0, 105)\n",
    "pred_y = np.clip(pred_y, 0, 68)\n",
    "\n",
    "# 4. 제출 파일 생성\n",
    "submission_df = pd.DataFrame({\n",
    "    'game_episode': test_ids,\n",
    "    'end_x': pred_x,\n",
    "    'end_y': pred_y\n",
    "})\n",
    "\n",
    "sample_submission = pd.read_csv(SUBMISSION_PATH)\n",
    "final_submission = pd.merge(sample_submission[['game_episode']], submission_df, on='game_episode', how='left')\n",
    "final_submission.fillna(50.0, inplace=True)\n",
    "\n",
    "save_path = 'submission_cat_optuna.csv'\n",
    "final_submission.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"\\nCatBoost 튜닝 완료! 결과 저장됨: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
