{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dl_001",
      "metadata": {},
      "source": [
        "# ğŸ§  Deep Learning: LSTM for Soccer Sequence Prediction\n",
        "\n",
        "ì´ ë…¸íŠ¸ëŠ” ì¶•êµ¬ ê²½ê¸°ì˜ **ì‹œí€€ìŠ¤(Sequence)** ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ **LSTM (Long Short-Term Memory)** ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
        "ë‹¨í¸ì ì¸ ìƒíƒœë§Œ ë³´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **\"íŒ¨ìŠ¤ -> ë“œë¦¬ë¸” -> ìŠ›\"**ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ë§¥ë½(Context)ì„ ì½ì–´ë‚´ì–´ ë§ˆì§€ë§‰ íŒ¨ìŠ¤ì˜ ë„ë‹¬ ìœ„ì¹˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ğŸš€ Key Strategy\n",
        "1. **Sequence Data Prep**: `game_episode` ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¬¶ì–´ ì‹œê³„ì—´ ì…ë ¥(3D Tensor)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "2. **Embedding Layers**: `player_id`, `type_name` ë“± ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "3. **LSTM Model**: ì‹œê°„ì˜ íë¦„ì— ë”°ë¥¸ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dl_002",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Dropout, Masking\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "# GPU í™•ì¸\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dl_003",
      "metadata": {},
      "source": [
        "## 1. Data Loading & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dl_004",
      "metadata": {},
      "outputs": [],
      "source": [
        "PREPROCESS_DIR = './data_preprocess'\n",
        "OPEN_DIR = './open_track1'\n",
        "\n",
        "# 1. Load Train (Feature Merged)\n",
        "# ìš°ë¦¬ê°€ ë§Œë“  'train_final.csv'ì—ëŠ” player_statsê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "train_df = pd.read_csv(os.path.join(PREPROCESS_DIR, 'train_final.csv'))\n",
        "\n",
        "# 2. Load Test (Full Sequence)\n",
        "# ì£¼ì˜: 'test_final.csv'ëŠ” ë§ˆì§€ë§‰ í–‰ë§Œ ì €ì¥í–ˆìœ¼ë¯€ë¡œ LSTMìš©ìœ¼ë¡œëŠ” ë¶€ì í•©í•©ë‹ˆë‹¤.\n",
        "# ë‹¤ì‹œ ì›ë³¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ì½ì–´ì„œ ì‹œí€€ìŠ¤ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "test_index = pd.read_csv(os.path.join(OPEN_DIR, 'test.csv'))\n",
        "player_stats = pd.read_csv(os.path.join(PREPROCESS_DIR, 'player_features.csv')) # Player stats ë‹¤ì‹œ ë¡œë“œ\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜\n",
        "def load_full_test_data(test_index, player_stats):\n",
        "    test_list = []\n",
        "    for idx, row in tqdm(test_index.iterrows(), total=len(test_index), desc=\"Loading Test Sequences\"):\n",
        "        file_path = os.path.join(OPEN_DIR, row['path'])\n",
        "        df = pd.read_csv(file_path)\n",
        "        \n",
        "        # Player Stats ë³‘í•©\n",
        "        df = pd.merge(df, player_stats, on='player_id', how='left')\n",
        "        \n",
        "        # ì‹ë³„ì ì¶”ê°€\n",
        "        df['game_episode'] = row['game_episode']\n",
        "        \n",
        "        test_list.append(df)\n",
        "    \n",
        "    return pd.concat(test_list, ignore_index=True)\n",
        "\n",
        "print(\"Loading Test Data...\")\n",
        "test_df = load_full_test_data(test_index, player_stats)\n",
        "\n",
        "# ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (Trainê³¼ ë™ì¼í•˜ê²Œ)\n",
        "fill_values = {\n",
        "    'avg_pass_dist': player_stats['avg_pass_dist'].mean(),\n",
        "    'avg_pass_angle': player_stats['avg_pass_angle'].mean(),\n",
        "    'pass_count': 0\n",
        "}\n",
        "test_df.fillna(fill_values, inplace=True)\n",
        "train_df.fillna(fill_values, inplace=True)\n",
        "\n",
        "print(f\"Train Shape: {train_df.shape}, Test Shape: {test_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dl_005",
      "metadata": {},
      "source": [
        "## 2. Sequence Generation (ì‹œí€€ìŠ¤ ë³€í™˜)\n",
        "LSTM í•™ìŠµì„ ìœ„í•´ `(Samples, Timesteps, Features)` í˜•íƒœì˜ 3D í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dl_006",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì‚¬ìš©í•  ë³€ìˆ˜ ì •ì˜\n",
        "NUMERIC_COLS = ['time_seconds', 'start_x', 'start_y', 'avg_pass_dist', 'avg_pass_angle']\n",
        "CAT_COLS = ['player_id', 'type_name'] # ì„ë² ë”©í•  ë³€ìˆ˜\n",
        "TARGET_COLS = ['end_x', 'end_y']\n",
        "\n",
        "# 1. Scaling (ìˆ˜ì¹˜í˜• ë³€ìˆ˜)\n",
        "scaler = StandardScaler()\n",
        "train_df[NUMERIC_COLS] = scaler.fit_transform(train_df[NUMERIC_COLS])\n",
        "test_df[NUMERIC_COLS] = scaler.transform(test_df[NUMERIC_COLS])\n",
        "\n",
        "# íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ë§ (0~105 -> 0~1ë¡œ í•˜ë©´ í•™ìŠµ ì•ˆì •ì„± ì¦ê°€)\n",
        "train_df['end_x'] = train_df['end_x'] / 105.0\n",
        "train_df['end_y'] = train_df['end_y'] / 68.0\n",
        "# í…ŒìŠ¤íŠ¸ëŠ” íƒ€ê²Ÿì´ NaNì´ë¯€ë¡œ íŒ¨ìŠ¤\n",
        "\n",
        "# 2. Encoding (ë²”ì£¼í˜• ë³€ìˆ˜)\n",
        "for col in CAT_COLS:\n",
        "    le = LabelEncoder()\n",
        "    # Trainê³¼ Testì˜ ëª¨ë“  ê°’ì„ í¬í•¨í•˜ì—¬ í”¼íŒ…\n",
        "    all_vals = pd.concat([train_df[col], test_df[col]]).astype(str).unique()\n",
        "    le.fit(all_vals)\n",
        "    \n",
        "    train_df[col] = le.transform(train_df[col].astype(str))\n",
        "    test_df[col] = le.transform(test_df[col].astype(str))\n",
        "    \n",
        "    print(f\"Encoded {col}: {len(le.classes_)} classes\")\n",
        "\n",
        "# 3. Sequence Padding Function\n",
        "MAX_LEN = 20 # ì‹œí€€ìŠ¤ ìµœëŒ€ ê¸¸ì´ (ë¶„ì„ ê²°ê³¼ í‰ê· ì´ ì‘ë‹¤ë©´ ì¤„ì—¬ë„ ë¨)\n",
        "\n",
        "def create_sequences(df, is_train=True):\n",
        "    # game_episode ë³„ë¡œ ê·¸ë£¹í™”\n",
        "    grouped = df.groupby('game_episode')\n",
        "    \n",
        "    seq_numeric = []\n",
        "    seq_cat1 = [] # player_id\n",
        "    seq_cat2 = [] # type_name\n",
        "    targets = []\n",
        "    ids = []\n",
        "    \n",
        "    for name, group in tqdm(grouped, desc=\"Creating Sequences\"):\n",
        "        # ì‹œê°„ìˆœ ì •ë ¬ (ì´ë¯¸ ë˜ì–´ìˆê² ì§€ë§Œ í™•ì‹¤íˆ)\n",
        "        # group = group.sort_values('time_seconds') # time_secondsê°€ ìŠ¤ì¼€ì¼ë§ë˜ì–´ ìˆì–´ë„ ì •ë ¬ì€ ìœ ì§€ë¨\n",
        "        \n",
        "        # Feature ì¶”ì¶œ\n",
        "        num_vals = group[NUMERIC_COLS].values\n",
        "        cat1_vals = group['player_id'].values\n",
        "        cat2_vals = group['type_name'].values\n",
        "        \n",
        "        # Trainì¸ ê²½ìš°: ë§ˆì§€ë§‰ í–‰ì˜ íƒ€ê²Ÿì„ ê°€ì ¸ì˜´\n",
        "        # í•˜ì§€ë§Œ ì…ë ¥ ì‹œí€€ìŠ¤ì—ëŠ” 'ë§ˆì§€ë§‰ í–‰'ê¹Œì§€ í¬í•¨í•´ì•¼ í•˜ëŠ”ê°€, ì•„ë‹ˆë©´ 'ë§ˆì§€ë§‰ í–‰ ì§ì „'ì¸ê°€?\n",
        "        # ë¬¸ì œ ì •ì˜: \"ì£¼ì–´ì§„ ì‹œí€€ìŠ¤ì˜ ë§ˆì§€ë§‰ íŒ¨ìŠ¤ ë„ì°© ì¢Œí‘œ\"\n",
        "        # ì¦‰, ë§ˆì§€ë§‰ í–‰(=ê·¸ íŒ¨ìŠ¤ ìì²´)ì˜ start_x, start_y, action_type ë“±ì€ ì•Œê³  ìˆìŒ.\n",
        "        # ë”°ë¼ì„œ ì…ë ¥ ì‹œí€€ìŠ¤ = [..., ì´ì „_í–‰, ë§ˆì§€ë§‰_í–‰]\n",
        "        \n",
        "        seq_numeric.append(num_vals)\n",
        "        seq_cat1.append(cat1_vals)\n",
        "        seq_cat2.append(cat2_vals)\n",
        "        ids.append(name)\n",
        "        \n",
        "        if is_train:\n",
        "            # ë§ˆì§€ë§‰ í–‰ì˜ end_x, end_yê°€ íƒ€ê²Ÿ\n",
        "            # ì£¼ì˜: group ìˆœì„œê°€ ì„ì´ì§€ ì•Šì•˜ë‹¤ë©´ iloc[-1]ì´ ë§ìŒ\n",
        "            target = group.iloc[-1][TARGET_COLS].values\n",
        "            targets.append(target)\n",
        "            \n",
        "    # Padding\n",
        "    # pre or post? LSTMì€ ë³´í†µ 'post' padding í›„ Masking ë ˆì´ì–´ ì‚¬ìš©í•˜ê±°ë‚˜, 'pre' padding ì‚¬ìš©.\n",
        "    # ìµœê·¼ íë¦„ì€ 'pre' (ë’¤ìª½ ê°’ì— ì§‘ì¤‘)ê°€ ì¢‹ë‹¤ê³  í•¨.\n",
        "    \n",
        "    X_num = pad_sequences(seq_numeric, maxlen=MAX_LEN, padding='pre', dtype='float32')\n",
        "    X_cat1 = pad_sequences(seq_cat1, maxlen=MAX_LEN, padding='pre', dtype='int32')\n",
        "    X_cat2 = pad_sequences(seq_cat2, maxlen=MAX_LEN, padding='pre', dtype='int32')\n",
        "    \n",
        "    if is_train:\n",
        "        y = np.array(targets, dtype='float32')\n",
        "        return [X_num, X_cat1, X_cat2], y, ids\n",
        "    else:\n",
        "        return [X_num, X_cat1, X_cat2], ids\n",
        "\n",
        "# Create Train Sequences\n",
        "X_train, y_train, train_ids = create_sequences(train_df, is_train=True)\n",
        "\n",
        "# Create Test Sequences\n",
        "X_test, test_ids = create_sequences(test_df, is_train=False)\n",
        "\n",
        "print(f\"X_train shape: {X_train[0].shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dl_007",
      "metadata": {},
      "source": [
        "## 3. Build & Train LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dl_008",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(num_len, cat1_vocab, cat2_vocab, emb_dim=16):\n",
        "    # Inputs\n",
        "    input_num = Input(shape=(None, num_len), name='numeric_in')\n",
        "    input_cat1 = Input(shape=(None,), name='player_in')\n",
        "    input_cat2 = Input(shape=(None,), name='type_in')\n",
        "    \n",
        "    # Embeddings\n",
        "    emb_cat1 = Embedding(input_dim=cat1_vocab, output_dim=emb_dim, mask_zero=True)(input_cat1)\n",
        "    emb_cat2 = Embedding(input_dim=cat2_vocab, output_dim=8, mask_zero=True)(input_cat2)\n",
        "    \n",
        "    # Concatenate: (Batch, Time, Features)\n",
        "    # Num inputë„ Masking ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆì§€ë§Œ, ë³´í†µ concat í›„ LSTMì´ ì²˜ë¦¬.\n",
        "    # Masking Layerë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë‘˜ ìˆ˜ë„ ìˆìŒ.\n",
        "    \n",
        "    concat = Concatenate()([input_num, emb_cat1, emb_cat2])\n",
        "    \n",
        "    # LSTM\n",
        "    x = LSTM(64, return_sequences=True)(concat)\n",
        "    x = LSTM(32)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    \n",
        "    # Output\n",
        "    output = Dense(2, activation='linear')(x) # x, y for normalized targets\n",
        "    \n",
        "    model = Model(inputs=[input_num, input_cat1, input_cat2], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Model Params\n",
        "num_features = X_train[0].shape[2]\n",
        "vocab_player = train_df['player_id'].max() + 1\n",
        "vocab_type = train_df['type_name'].max() + 1\n",
        "\n",
        "model = build_model(num_features, vocab_player, vocab_type)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dl_009",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training with Validation Loop (ê°„ë‹¨íˆ holdout or k-fold)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10 \n",
        "# ì‹œê°„ ê´€ê³„ìƒ Epochì„ ì ê²Œ ì¡ì•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” EarlyStoppingì´ ë©ˆì¶œ ë•Œê¹Œì§€ í•´ì•¼ í•¨.\n",
        "\n",
        "checkpoint = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1)\n",
        "\n",
        "# Split Train/Val (based on IDs to avoid leakage)\n",
        "# ê°„ë‹¨í•˜ê²Œ slicing\n",
        "val_ratio = 0.2\n",
        "val_cnt = int(len(X_train[0]) * val_ratio)\n",
        "\n",
        "X_train_fold = [x[:-val_cnt] for x in X_train]\n",
        "y_train_fold = y_train[:-val_cnt]\n",
        "X_val_fold = [x[-val_cnt:] for x in X_train]\n",
        "y_val_fold = y_train[-val_cnt:]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_fold, y_train_fold,\n",
        "    validation_data=(X_val_fold, y_val_fold),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dl_010",
      "metadata": {},
      "source": [
        "## 4. Inference & Submission\n",
        "í•™ìŠµëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì¢Œí‘œë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dl_011",
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = model.predict(X_test, batch_size=BATCH_SIZE)\n",
        "\n",
        "# ìŠ¤ì¼€ì¼ë§ ë³µêµ¬ (0~1 -> 0~105)\n",
        "preds[:, 0] = preds[:, 0] * 105.0\n",
        "preds[:, 1] = preds[:, 1] * 68.0\n",
        "\n",
        "# Clipping (ê²½ê¸°ì¥ ë°–ìœ¼ë¡œ ë‚˜ê°€ì§€ ì•Šê²Œ ë³´ì •)\n",
        "preds[:, 0] = np.clip(preds[:, 0], 0, 105)\n",
        "preds[:, 1] = np.clip(preds[:, 1], 0, 68)\n",
        "\n",
        "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "submission = pd.DataFrame({\n",
        "    'game_episode': test_ids,\n",
        "    'end_x': preds[:, 0],\n",
        "    'end_y': preds[:, 1]\n",
        "})\n",
        "\n",
        "# ì •ë ¬ (ì œì¶œì€ sample_submission ìˆœì„œì™€ ìƒê´€ì—†ì„ ìˆ˜ ìˆìœ¼ë‚˜ ë§ì¶”ëŠ”ê²Œ ì¢‹ìŒ)\n",
        "# sample_submission ë¡œë“œ\n",
        "sample_sub = pd.read_csv('./open_track1/sample_submission.csv')\n",
        "# game_episode ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•˜ì—¬ ìˆœì„œ ë§ì¶¤\n",
        "final_sub = pd.merge(sample_sub[['game_episode']], submission, on='game_episode', how='left')\n",
        "\n",
        "save_path = 'submission_lstm.csv'\n",
        "final_sub.to_csv(save_path, index=False)\n",
        "print(f\"Saved Submission: {save_path}\")\n",
        "final_sub.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
